---
title: "Analysis of False Belief Task"
author: "Sean Trott"
date: "April 24, 2025"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "png")
```


```{r include=FALSE}
library(tidyverse)
library(lmtest)
library(forcats)
library(broom)
library(lme4)
library(viridis)
library(ggridges)
library(lmerTest)
library(ggrepel)
library(ggcorrplot)

all_colors <- viridis::viridis(10, option = "mako")
my_colors <- all_colors[c(3, 5, 7)]  # Selecting specific colors from the palette
```

# Load LLM data

```{r}
# setwd("/Users/seantrott/Dropbox/UCSD/Research/NLMs/open_llm_tom/src/analysis")
directory_path <- "../../data/processed/fb_all/"
csv_files <- list.files(path = directory_path, pattern = "*.csv", full.names = TRUE)
csv_list <- csv_files %>%
  map(~ read_csv(.))
df_all_models <- bind_rows(csv_list) %>%
  mutate(model_shorthand = str_to_title(model_shorthand))
nrow(df_all_models)


length(unique(df_all_models$model_shorthand))
table(df_all_models$model_path)
table(df_all_models$model_shorthand)



### Load #params
df_model_properties = read_csv("../../data/processed/model_properties.csv") %>% 
  mutate(model_shorthand = str_to_title(model_shorthand))
nrow(df_model_properties)

### Load training data
df_training_data = read_csv("../../data/processed/model_training_data.csv")%>% 
  mutate(model_shorthand = str_to_title(model_shorthand))
table(df_training_data$model_shorthand)

### Join
df_all_properties = df_training_data %>%
  inner_join(df_model_properties)

table(df_all_properties$model_shorthand)
nrow(df_all_properties)


#### Bind with FB data
df_all_models = df_all_models %>%
  inner_join(df_all_properties)
nrow(df_all_models)
table(df_all_models$model_shorthand)

df_all_models = df_all_models %>%
  mutate(model_shorthand = str_to_title(model_shorthand))


length(unique(df_all_models$model_shorthand))
length(unique(df_all_models$model_family))

```


# LLM Analysis

## Sensitivity to mental states

```{r}
### Visualization
df_all_models %>%
  ggplot(aes(x = log_odds,
             y = reorder(model_shorthand, num_params),
             fill = condition)) +
  geom_density_ridges2(aes(height = ..density..), 
                       color=NA, 
                       scale=.85, 
                       # size=1, 
                       alpha = .8,
                       stat="density") +
  labs(x = "Log Odds (Start vs. End)",
       y = "",
       fill = "") +
  theme_minimal() +
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme(
    legend.position = "bottom"
  ) + 
  theme(axis.title = element_text(size=rel(1.2)),
        axis.text = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)),
        strip.text.x = element_text(size = rel(1.2))) +
    scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                    begin = 0.8, end = 0.15)) +
  facet_wrap(~knowledge_cue)

### Visualization by model family
df_all_models %>%
  group_by(passage, condition, knowledge_cue, model_family) %>%
  summarise(m_lo = mean(log_odds)) %>%
  ggplot(aes(x = m_lo,
             y = model_family,
             fill = condition)) +
  geom_density_ridges2(aes(height = ..density..), 
                       color=NA, 
                       scale=.85, 
                       # size=1, 
                       alpha = .8,
                       stat="density") +
  labs(x = "Log Odds (Start vs. End)",
       y = "",
       fill = "") +
  theme_minimal() +
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme(
    legend.position = "bottom"
  ) + 
  theme(axis.title = element_text(size=rel(1.2)),
        axis.text = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)),
        strip.text.x = element_text(size = rel(1.2))) +
    scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                    begin = 0.8, end = 0.15)) +
  facet_wrap(~knowledge_cue)

### Visualization altogether
df_all_models %>%
  group_by(passage, condition, knowledge_cue) %>%
  summarise(m_lo = mean(log_odds)) %>%
  ggplot(aes(x = m_lo,
             y = knowledge_cue,
             fill = condition)) +
  geom_density_ridges2(aes(height = ..density..), 
                       color=NA, 
                       scale=.85, 
                       # size=1, 
                       alpha = .8,
                       stat="density") +
  labs(x = "Log Odds (Start vs. End)",
       y = "",
       fill = "") +
  theme_minimal() +
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme(
    legend.position = "bottom"
  ) + 
  theme(axis.title = element_text(size=rel(1.2)),
        axis.text = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)),
        strip.text.x = element_text(size = rel(1.2))) +
    scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                    begin = 0.8, end = 0.15))




```

Each model on its own:

```{r}
# Function to fit models and perform model comparison
compare_models <- function(df) {
  if (n_distinct(df$condition) < 2) return(NULL)  # Skip if only one condition
  
  mod_full <- tryCatch(
    lmer(log_odds ~ condition + knowledge_cue + first_mention + recent_mention +
           (1 + condition | start), data = df, REML = FALSE),
    error = function(e) NULL
  )
  
  mod_reduced <- tryCatch(
    lmer(log_odds ~ knowledge_cue + first_mention + recent_mention +
           (1 + condition | start), data = df, REML = FALSE),
    error = function(e) NULL
  )
  
  if (is.null(mod_full) || is.null(mod_reduced)) return(NULL)
  
  anova_result <- anova(mod_full, mod_reduced)
  delta_aic <- AIC(mod_reduced) - AIC(mod_full)
  lrt_stat <- anova_result$Chisq[2]
  p_val <- anova_result$`Pr(>Chisq)`[2]
  
  # Extract coefficients
  coefs <- tryCatch(fixef(mod_full), error = function(e) return(rep(NA, 2)))
  cond_coef <- coefs[grep("^condition", names(coefs))]
  cue_coef <- coefs[grep("^knowledge_cue", names(coefs))]

  tibble(
    model_path = unique(df$model_path),
    delta_AIC = delta_aic,
    LRT_stat = lrt_stat,
    p_value = p_val,
    condition_coef = cond_coef,
    knowledge_cue_coef = cue_coef
  )
}

# Apply to each model_path
results_by_model_path <- df_all_models %>%
  group_by(model_path) %>%
  group_split() %>%
  map_dfr(compare_models)
results_by_model_path %>%
  arrange(LRT_stat)

summary(results_by_model_path$LRT_stat)
summary(results_by_model_path$condition_coef)
summary(results_by_model_path$knowledge_cue_coef)


### TODO: Should we adjust? What hypothesis are we testing?
results_by_model_path$p_adj = p.adjust(results_by_model_path$p_value, method = "holm")
results_by_model_path = results_by_model_path %>%
  mutate(sig = p_adj < .05)
mean(results_by_model_path$sig)

results_by_model_path %>%
  filter(sig == TRUE) %>%
  select(model_path, LRT_stat, p_adj, condition_coef)
```


All models together:

```{r}

### Mixed models
mod_full = lmer(data = df_all_models,
                log_odds ~ condition + knowledge_cue + first_mention + recent_mention + 
                  (1 + condition | model_path) + (1 + condition | start),
                REML = FALSE)

mod_reduced = lmer(data = df_all_models,
                log_odds ~ knowledge_cue + first_mention + recent_mention + 
                  (1 + condition | model_path) + (1 + condition | start),
                REML = FALSE)

summary(mod_full)
anova(mod_full, mod_reduced)
```


## Accuracy metric


```{r}
df_all_models = df_all_models %>%
  mutate(correct = case_when(
    condition == "False Belief" & log_odds > 0 ~ TRUE,
    condition == "True Belief" & log_odds <= 0 ~ TRUE,
    TRUE ~ FALSE  # all other cases are incorrect
  ))


df_summ = df_all_models %>%
  group_by(model_path, model_shorthand, model_family,
           num_params, num_training_tokens, base_instruct) %>%
  summarise(mean_accuracy = mean(correct))
df_summ %>%
  select(model_shorthand, mean_accuracy)
mean(df_all_models$correct)

df_summ %>%
  ungroup() %>%
  arrange(desc(mean_accuracy)) %>%
  select(model_shorthand, mean_accuracy) %>%
  head(5)


### "Wisdom of the crowd"?
df_lo_avg = df_all_models %>%
  group_by(passage, condition) %>%
  summarise(m_lo = mean(log_odds)) %>%
  mutate(correct = case_when(
    condition == "False Belief" & m_lo > 0 ~ TRUE,
    condition == "True Belief" & m_lo <= 0 ~ TRUE,
    TRUE ~ FALSE  # all other cases are incorrect
  )) 
mean(df_lo_avg$correct)



df_summ %>%
  ggplot(aes(x = num_params,
             y = mean_accuracy,
             color = model_family,
             shape = base_instruct)) +
  geom_point(size = 6,
             alpha = .5) +
  geom_hline(yintercept = .83,##TODO: Calculate from scratch
             linetype = "dotted", color = "red",
             size = 1.2, alpha = .8) + 
    geom_hline(yintercept = .9,##TODO: Calculate from scratch
             linetype = "dotted", color = "blue",
             size = 1.2, alpha = .8) + 
  geom_hline(yintercept = .5, linetype = "dotted",
             size = 1.2, alpha = .5) +
  scale_x_log10() +
  # geom_text_repel(aes(label=model_shorthand), size=3) +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Parameters",
       y = "Accuracy",
       color = "",
       shape = "") +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  theme(text = element_text(size = 15),
        legend.position="bottom")

df_summ %>%
  ggplot(aes(x = num_training_tokens,
             y = mean_accuracy,
             color = model_family,
             shape = base_instruct)) +
  geom_point(size = 6,
             alpha = .5) +
  geom_hline(yintercept = .83,##TODO: Calculate from scratch
             linetype = "dotted", color = "red",
             size = 1.2, alpha = .8) + 
  geom_hline(yintercept = .5, linetype = "dotted",
             size = 1.2, alpha = .5) +
    geom_hline(yintercept = .9,##TODO: Calculate from scratch
             linetype = "dotted", color = "blue",
             size = 1.2, alpha = .8) + 
  scale_x_log10() +
  # geom_text_repel(aes(label=model_shorthand), size=3) +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "#Training Tokens",
       y = "Accuracy",
       color = "",
       shape = "") +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  theme(text = element_text(size = 15),
        legend.position="bottom")



### How do model properties predict the probability of a correct response?
mod_full = glmer(data = df_all_models,
                 correct ~ condition + knowledge_cue  +
                   log10(num_params) + log10(num_training_tokens) + 
                  base_instruct + 
                   (1 | start) + (1|model_family), 
                 family = binomial())
summary(mod_full)



### Plot coefficients
df_coef <- broom.mixed::tidy(mod_full, effects = "fixed") %>%
  mutate(term = forcats::fct_reorder(term, estimate))


df_coef %>%
  filter(term != "(Intercept)") %>%
  ggplot(aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
  coord_flip() +
  labs(
    x = NULL, y = "Coefficient Estimate",
  ) +
  theme_minimal(base_size = 12)

```

## Item-wise analysis

```{r}
df_item_accuracy = df_all_models %>%
  group_by(start) %>%
  summarise(mean_accuracy = mean(correct)) %>%
  arrange(mean_accuracy)

df_item_accuracy %>%
  ggplot(aes(x = reorder(start, mean_accuracy), y = mean_accuracy)) +
  geom_bar(stat = "identity", alpha = .6) +
  labs(x = "Item",
       y = "Mean Accuracy",
       color = "",
       shape = "") +
  theme_minimal() +
  geom_hline(linetype = "dotted", yintercept = .5) +
  coord_flip() +
  theme(text = element_text(size = 15),
        legend.position="bottom")
  
```



# Comparison to human baseline

## Load human data

```{r}
df_human = read_csv("../../data/processed/human/human_fb_cleaned.csv") %>%
  select(participant_id, item_id, passage,
         is_correct, is_start, is_end,
         reaction_time, condition, response, first_mention, recent_mention, knowledge_cue)
mean(df_human$is_correct)

df_by_item = df_human %>%
  group_by(condition, passage, knowledge_cue) %>%
  summarise(p_start = mean(is_start) + .0001,
            p_end = mean(is_end) + .0001) %>%
  mutate(log_odds = log((p_start / p_end))) %>%
  mutate(model_shorthand = "Human") %>%
  mutate(correct = case_when(
    condition == "False Belief" & log_odds > 0 ~ TRUE,
    condition == "True Belief" & log_odds <= 0 ~ TRUE,
    TRUE ~ FALSE  # all other cases are incorrect
  ))
### Mean using log-odds measure forh umans
mean(df_by_item$correct)



### Merge
df_merged = df_all_models %>%
  bind_rows(df_by_item)
```


## Top-performing models

```{r}
df_merged %>%
  filter(model_shorthand %in% c("Human",
                                "Olmo 2 13b Dpo",
                                "Olmo 2 13b Instruct",
                                "Olmo 2 13b Sft",
                                "Llama 3 70b Instruct",
                                "Olmo 2 13b")) %>%
  ggplot(aes(x = log_odds,
             y = model_shorthand,
             fill = condition)) +
  geom_density_ridges2(aes(height = ..density..), 
                       color=NA, 
                       scale=.85, 
                       # size=1, 
                       alpha = .8,
                       stat="density") +
  labs(x = "Log Odds (Start vs. End)",
       y = "",
       fill = "") +
  theme_minimal() +
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme(
    legend.position = "bottom"
  ) + 
  theme(axis.title = element_text(size=rel(1.2)),
        axis.text = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)),
        strip.text.x = element_text(size = rel(1.2))) +
    scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                    begin = 0.8, end = 0.15)) +
  facet_wrap(~knowledge_cue)

```



## Correlation matrix

```{r}
df_model_means = df_all_models %>%
  group_by(passage, condition, knowledge_cue) %>%
  summarise(log_odds = mean(log_odds)) %>%
  mutate(model_shorthand = "All Models")

# df_merged = df_merged %>%
#   bind_rows(df_model_means)


df_wide <- df_merged %>%
  select(passage, model_shorthand, log_odds) %>%
  pivot_wider(names_from = model_shorthand, values_from = log_odds)

cor_matrix <- df_wide %>%
  select(-passage) %>%
  cor(use = "pairwise.complete.obs")
cor_matrix

# Plot the correlation matrix
ggcorrplot(cor_matrix, 
           hc.order = FALSE,
           method = "square" 
          ) +
  theme(
    axis.text.x = element_text(size = 6, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 6)
  )

sort(cor_matrix["Human",])


### MDS
# Convert correlation matrix to a dissimilarity matrix
dissimilarity <- as.dist(sqrt(1 - cor_matrix))

# Perform classical MDS
mds_result <- cmdscale(dissimilarity, k = 2)  # k = number of dimensions, usually 2 for plotting

# Put into a data frame for plotting
mds_df <- as.data.frame(mds_result)
colnames(mds_df) <- c("Dim1", "Dim2")
mds_df$model_shorthand <- rownames(mds_df)

mds_df = mds_df %>%
  inner_join(df_summ)



cor(mds_df$Dim1, mds_df$mean_accuracy)
cor(mds_df$Dim2, mds_df$mean_accuracy)


mds_df = mds_df %>%
  inner_join(results_by_model_path)


ggplot(mds_df, aes(Dim1, Dim2, 
                   color = model_family,
                   size = mean_accuracy,
                   shape = sig)) +
  geom_point(alpha = .5) +
  theme_minimal() +
  labs(x = "MDS 1",
       y = "MDS 2",
       color = "") +
  theme(text = element_text(size = 15),
        legend.position = "none") +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                   begin = 0.8, end = 0.15)) 



```


## Baselines analysis

First, merge with raw human data.

```{r}
df_human_shortened = df_human %>%
  # mutate(human_is_start = is_start) %>%
  select(participant_id, item_id, passage, condition, knowledge_cue, 
         is_start, reaction_time)

df_all_models_with_human = df_all_models %>%
  inner_join(df_human_shortened)

table(df_all_models_with_human$model_path)

```

Now, fit a baselines model for each LLM.


```{r}
fit_compare_glmer_by_model <- function(df) {
  if (n_distinct(df$is_start) < 2) return(NULL)  # skip degenerate cases

  # Fit full model
  mod_full <- tryCatch(
    glmer(is_start ~ condition + knowledge_cue + 
            first_mention + recent_mention + log_odds +
            (1 | item_id),
          data = df,
          family = binomial()),
    error = function(e) NULL
  )

  # Fit reduced model (no condition)
  mod_reduced <- tryCatch(
    glmer(is_start ~ knowledge_cue + 
            first_mention + recent_mention + log_odds +
            (1 | item_id),
          data = df,
          family = binomial()),
    error = function(e) NULL
  )

  if (is.null(mod_full) || is.null(mod_reduced)) return(NULL)

  # Model comparison (Likelihood Ratio Test)
  anova_result <- anova(mod_reduced, mod_full)
  lrt_stat <- anova_result$Chisq[2]
  p_val <- anova_result$`Pr(>Chisq)`[2]
  delta_aic <- AIC(mod_reduced) - AIC(mod_full)

  # Extract coefficient for log_odds
  log_odds_coef <- tryCatch({
    fixef(mod_full)["log_odds"]
  }, error = function(e) NA)

  tibble(
    model_shorthand = unique(df$model_shorthand),
    delta_AIC = delta_aic,
    LRT_stat = lrt_stat,
    p_value = p_val,
    log_odds_coef = log_odds_coef,
    knowledge_cue_coef = fixef(mod_full)["knowledge_cueImplicit"],
    condition_coef = fixef(mod_full)["conditionTrue Belief"],
    
  )
}

# Apply across model_shorthand groups
glmer_model_comparisons <- df_all_models_with_human %>%
  group_by(model_shorthand) %>%
  group_split() %>%
  map_dfr(fit_compare_glmer_by_model)

glmer_model_comparisons

summary(glmer_model_comparisons$log_odds_coef)
summary(glmer_model_comparisons$knowledge_cue_coef)
summary(glmer_model_comparisons$condition_coef)
summary(glmer_model_comparisons$LRT_stat)

```

## PPP Analysis

```{r}
fit_ppp_by_model <- function(df) {

  # Fit full model
  mod_full <- tryCatch(
    glmer(is_start ~ log_odds+
            (1 | item_id),
          data = df,
          family = binomial()),
    error = function(e) NULL
  )

  # Extract coefficient for log_odds
  log_odds_coef <- tryCatch({
    fixef(mod_full)["log_odds"]
  }, error = function(e) NA)

  tibble(
    model_shorthand = unique(df$model_shorthand),
    AIC = AIC(mod_full),
    log_odds_coef = fixef(mod_full)["log_odds"]
  )
}

# Apply across model_shorthand groups
ppp_models <- df_all_models_with_human %>%
  group_by(model_shorthand) %>%
  group_split() %>%
  map_dfr(fit_ppp_by_model) %>%
  inner_join(df_model_properties)

### Rescale AIC
ppp_models = ppp_models %>%
  mutate(delta_AIC = AIC - min(AIC),
         weight = exp(-0.5 * delta_AIC),
         model_prob = weight / sum(weight))


### Add back to original data
ppp_with_accuracy = ppp_models %>%
  select(model_shorthand, model_prob, delta_AIC) %>%
  inner_join(df_summ)

ppp_with_accuracy %>%
  summarise(
    weighted_accuracy = sum(mean_accuracy * model_prob),
    mean_accuracy = mean(mean_accuracy)
  )


ppp_with_accuracy %>%
  ggplot(aes(x = num_training_tokens,
             y = delta_AIC,
             color = model_family,
             shape = base_instruct)) +
  geom_point(size = 6,
             alpha = .5) +
  scale_x_log10() +
  geom_text_repel(aes(label=model_shorthand), size=3) +
  labs(x = "#Training Tokens",
       y = "Delta AIC",
       color = "",
       shape = "") +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  theme(text = element_text(size = 15),
        legend.position="bottom")


ppp_with_accuracy %>%
  ggplot(aes(x = num_params,
             y = delta_AIC,
             color = model_family,
             shape = base_instruct)) +
  geom_point(size = 6,
             alpha = .5) +
  scale_x_log10() +
  geom_text_repel(aes(label=model_shorthand), size=3) +
  labs(x = "#Parameters",
       y = "Delta AIC",
       color = "",
       shape = "") +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  theme(text = element_text(size = 15),
        legend.position="bottom")

### Among models that >50% accuracy, better models explain more variance in human data
ppp_with_accuracy %>%
  ggplot(aes(x = mean_accuracy,
             y = delta_AIC,
             color = model_family,
             shape = base_instruct)) +
  geom_point(size = 6,
             alpha = .5) +
  scale_x_log10() +
  geom_text_repel(aes(label=model_shorthand), size=3) +
  labs(x = "Accuracy",
       y = "Delta AIC",
       color = "",
       shape = "") +
  theme_minimal() +
  scale_color_manual(values = viridisLite::viridis(8, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  theme(text = element_text(size = 15),
        legend.position="bottom")



mod_ppp = lmer(data = ppp_with_accuracy,
               delta_AIC ~ # mean_accuracy + 
                 log10(num_params) + log10(num_training_tokens)+
                 (1 | model_family))

summary(mod_ppp)
```


## Knowledge cue

```{r}
mod_full = glmer(is_start ~ condition + knowledge_cue + 
          first_mention + recent_mention +
          (1 | item_id),
        data = df_human,
        family = binomial())
mod_no_kc = glmer(is_start ~ condition + # knowledge_cue + 
          first_mention + recent_mention +
          (1 | item_id),
        data = df_human,
        family = binomial())

anova(mod_full, mod_no_kc)
summary(mod_full)



### Comopare to parameter estimate for LLMs, using binary outcome
df_all_models$is_start = df_all_models$log_odds > 0


coef_human <- fixef(mod_full)

# Create aligned dataframe
group_coefs <- tibble(
  model_path = c("Human"),
  knowledge_cue_coef = c(coef_human["knowledge_cueImplicit"]),
  condition_coef = c(coef_human["conditionTrue Belief"])
)

## Each model on its own
run_models_for_comparison <- function(df) {

  mod_full = glmer(is_start ~ condition + knowledge_cue + 
            first_mention + recent_mention +
            (1 + condition | start),
          data = df,
          family = binomial(),
          control = glmerControl(optimizer = "bobyqa"))
  
  # Extract coefficients
  coefs <- fixef(mod_full)
  cond_coef <- coefs[grep("^condition", names(coefs))]
  cue_coef <- coefs[grep("^knowledge_cue", names(coefs))]

  tibble(
    model_path = unique(df$model_path),
    condition_coef = cond_coef,
    knowledge_cue_coef = cue_coef
  )
}

# Apply to each model_path
results_by_model_path <- df_all_models %>%
  group_by(model_path) %>%
  group_split() %>%
  map_dfr(run_models_for_comparison)


all_coefs = results_by_model_path %>%
  select(model_path, knowledge_cue_coef, condition_coef) %>%
  bind_rows(group_coefs)



all_coefs_long = all_coefs %>%
  pivot_longer(cols = c(knowledge_cue_coef, condition_coef),
              names_to = "Term",
               values_to = "Estimate") %>%
  mutate(Term = fct_recode(Term, 
                           "Knowledge Cue (Implicit)" = "knowledge_cue_coef",
                           "Condition (True Belief)" = "condition_coef"))


reference_coefs <- all_coefs_long %>%
  filter(model_path %in% c("Human", "LLMs"))

all_coefs_long %>%
  filter(model_path != "Human") %>%
  filter(model_path != "LLMs") %>%
  ggplot(aes(x = Term,
             y = Estimate)) +
  geom_jitter(width = .05, alpha = .3) +
  geom_point(data = reference_coefs,
             aes(x = Term, y = Estimate, color = model_path),
             size = 6,
             alpha = .8,
             shape = 18, 
             inherit.aes = FALSE) +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme(
    legend.position = "bottom"
  ) + 
  labs(x = "",
       color = "") + 
  coord_flip() +
  theme(axis.title = element_text(size=rel(1.2)),
        axis.text = element_text(size = rel(1.2)),
        legend.text = element_text(size = rel(1.2)),
        legend.title = element_text(size = rel(1.2)),
        strip.text.x = element_text(size = rel(1.2))) +
    scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                    begin = 0.8, end = 0.15))


```


